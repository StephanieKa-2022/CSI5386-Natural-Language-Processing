{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yyyhpets2022/CSI5386-Natural-Language-Processing/blob/main/CSI_5386_NPL_Assignment_1_Part_2_%7C_Doc2Vec.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instructions before running the program:\n",
        "1.   Add the text file in your program (if needed)\n",
        "2.   Copy the name of the file\n",
        "3.   Please update the name under which the CSV will be saved in each section \n",
        "\n",
        "Description:\n",
        "*   The following program implement 1 sentence embedding model: Doc2Vec\n",
        "*   Each models results will be saved as CSV containing 4 columns: Sentence 1, Sentence 2, and two sets of similarity scores"
      ],
      "metadata": {
        "id": "iwsvZravPsQZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Doc2Vec"
      ],
      "metadata": {
        "id": "9xswahpJ2TQ3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jXH5Lw1fuBUt"
      },
      "outputs": [],
      "source": [
        "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
        "from nltk.tokenize import word_tokenize\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TeoeRMVDuDJq"
      },
      "outputs": [],
      "source": [
        "with open('STS2016.input.question-question.txt') as f:\n",
        "    lines = str(f.readlines())\n",
        "s1=str(lines).split('\\\\n')\n",
        "line1=[]\n",
        "line2=[]\n",
        "for i in range(0,len(s1)-1):\n",
        "  line1.append(s1[i].split('\\\\t')[0])\n",
        "  line2.append(s1[i].split('\\\\t')[1])\n",
        "import re\n",
        "string1=[]\n",
        "for i in line1:\n",
        "  string1.append(re.sub(r\"[^a-zA-Z0-9]+\",' ',i))\n",
        "string2=[]\n",
        "for i in line2:\n",
        "  string2.append(re.sub(r\"[^a-zA-Z0-9]+\",' ',i))\n",
        "strin=string1 +string2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SfTDLc4luID1"
      },
      "outputs": [],
      "source": [
        "tokenized_doc = []\n",
        "for d in strin:\n",
        "    tokenized_doc.append(word_tokenize(d.lower()))\n",
        "#print(len(tokenized_doc))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xVA7iR0Guhov"
      },
      "outputs": [],
      "source": [
        "# Convert tokenized document into gensim formated tagged data\n",
        "tagged_data = [TaggedDocument(d, [i]) for i, d in enumerate(tokenized_doc)]\n",
        "tagged_data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m8kl--DVuqXr"
      },
      "outputs": [],
      "source": [
        "## Train doc2vec model\n",
        "model = Doc2Vec(tagged_data, vector_size=20, window=2, min_count=1, workers=4, epochs = 100)\n",
        "# Save trained doc2vec model\n",
        "model.save(\"test_doc2vec.model\")\n",
        "## Load saved doc2vec model\n",
        "model= Doc2Vec.load(\"test_doc2vec.model\")\n",
        "## Print model vocabulary\n",
        "model.wv.vocab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LHkJLQAssUvs"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# !pip install -U sentence-transformers\n",
        "# from sentence_transformers import SentenceTransformer, util\n",
        "# model1 = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "import numpy as np\n",
        "def cosine(u, v):\n",
        "    return np.dot(u, v) / (np.linalg.norm(u) * np.linalg.norm(v))\n",
        "\n",
        "x=0\n",
        "similar=[]\n",
        "for i in range(len(string1)):\n",
        "  query_vec1 = model.infer_vector(string1[i])\n",
        "  query_vec2 = model.infer_vector(string2[i])\n",
        "  sim = cosine(query_vec1, query_vec2)\n",
        "  print(\"Sentence = \", string1[i], string2[i], \"; similarity = \", sim)\n",
        "  similar.append(sim)\n",
        "  x=x+1\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(similar)"
      ],
      "metadata": {
        "id": "gmbe3nPEvFrC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tnM4Ggmqu3_O"
      },
      "outputs": [],
      "source": [
        "similarity_score=[element * 5 for element in similar]\n",
        "print(similarity_score)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_doc2vec = pd.DataFrame(list(zip(string1, string2, similar, similarity_score)),\n",
        "               columns =['Sentence 1', 'Sentence 2', 'Score Doc2Vec', 'Score Doc2Vec times 5'])\n",
        "df_doc2vec.head()"
      ],
      "metadata": {
        "id": "X9AoaKOhzMZf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CSV creation: This is where you can update the CSV name"
      ],
      "metadata": {
        "id": "w9aVRRbDP2lT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "csv_doc2vec_name = r'STS2016.input.question-question.csv'\n",
        "df_doc2vec.to_csv(csv_doc2vec_name, index = False)"
      ],
      "metadata": {
        "id": "iMT05Q2E-LEs"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}